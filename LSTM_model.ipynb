{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suhana830/next_word_prediction_using_LSTM/blob/main/LSTM_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3Mr3DFpWzwZg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iH9qfPZC0As-",
        "outputId": "66da74ad-3ca8-46d8-f6d5-a288ed2bde26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               quote           Author\n",
              "0  “The world as we have created it is a process ...  Albert Einstein\n",
              "1  “It is our choices, Harry, that show what we t...     J.K. Rowling\n",
              "2  “There are only two ways to live your life. On...  Albert Einstein\n",
              "3  “The person, be it gentleman or lady, who has ...      Jane Austen\n",
              "4  “Imperfection is beauty, madness is genius and...   Marilyn Monroe"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85a8db4c-cb8e-4b2d-be76-98bb23bf8ff2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quote</th>\n",
              "      <th>Author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“The world as we have created it is a process ...</td>\n",
              "      <td>Albert Einstein</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>“It is our choices, Harry, that show what we t...</td>\n",
              "      <td>J.K. Rowling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“There are only two ways to live your life. On...</td>\n",
              "      <td>Albert Einstein</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
              "      <td>Jane Austen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85a8db4c-cb8e-4b2d-be76-98bb23bf8ff2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85a8db4c-cb8e-4b2d-be76-98bb23bf8ff2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85a8db4c-cb8e-4b2d-be76-98bb23bf8ff2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3038,\n  \"fields\": [\n    {\n      \"column\": \"quote\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3037,\n        \"samples\": [\n          \"Would it save you a lot of time if I just gave up and went mad now?\",\n          \"\\u0627\\u0644\\u0643\\u0631\\u0627\\u0647\\u064a\\u0629 \\u062a\\u0643\\u0644\\u0641 \\u0623\\u0643\\u062b\\u0631 \\u0645\\u0646 \\u0627\\u0644\\u062d\\u0628.. \\u0644\\u0623\\u0646\\u0647\\u0627 \\u0625\\u062d\\u0633\\u0627\\u0633 \\u063a\\u064a\\u0631 \\u0637\\u0628\\u064a\\u0639\\u064a.. \\u0625\\u062d\\u0633\\u0627\\u0633 \\u0639\\u0643\\u0633\\u064a \\u0645\\u062b\\u0644 \\u062d\\u0631\\u0643\\u0629 \\u0627\\u0644\\u0623\\u062c\\u0633\\u0627\\u0645 \\u0636\\u062f \\u062c\\u0627\\u0630\\u0628\\u064a\\u0629 \\u0627\\u0644\\u0623\\u0631\\u0636.. \\u062a\\u062d\\u062a\\u0627\\u062c \\u0625\\u0644\\u0649 \\u0642\\u0648\\u0629 \\u0625\\u0636\\u0627\\u0641\\u064a\\u0629 \\u0648\\u062a\\u0633\\u062a\\u0647\\u0644\\u0643 \\u0648\\u0642\\u0648\\u062f\\u0627\\u064b \\u0623\\u0643\\u062b\\u0631\",\n          \"The only thing worse than a boy who hates you: a boy that loves you.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Author\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1005,\n        \"samples\": [\n          \"Ashleigh Brilliant\",\n          \"Chuck Klosterman,\",\n          \"Coco Chanel,\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df = pd.read_csv(\"qoute_dataset.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEiekfik0DpU",
        "outputId": "2242b403-a3fc-40f3-9472-caa880592417"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3038, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaViE3El0Kq-",
        "outputId": "96b388e2-4f8f-4c54-84bc-ecc6abc4e8fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3038 entries, 0 to 3037\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   quote   3038 non-null   object\n",
            " 1   Author  3038 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 47.6+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TmxhKeB60VXH"
      },
      "outputs": [],
      "source": [
        "quotes = df['quote']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "95u2k2pF1GuF"
      },
      "outputs": [],
      "source": [
        "quotes = quotes.str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mknh3K6N28o5"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "quotes = quotes.apply(remove_punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfUbxIad1Qn1",
        "outputId": "2a64a7a9-cf58-472d-a9df-8e730d704301"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8978"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "unique_words = set(\n",
        "    \" \".join(quotes.astype(str)).split()\n",
        ")\n",
        "\n",
        "len(unique_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5SBa8MK2GLn",
        "outputId": "63039514-d7f5-471d-8d50-996b32cab990"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[713,\n",
              " 62,\n",
              " 29,\n",
              " 19,\n",
              " 16,\n",
              " 946,\n",
              " 10,\n",
              " 7,\n",
              " 5,\n",
              " 1156,\n",
              " 8,\n",
              " 70,\n",
              " 293,\n",
              " 10,\n",
              " 145,\n",
              " 12,\n",
              " 809,\n",
              " 104,\n",
              " 752,\n",
              " 70,\n",
              " 2461]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=len(unique_words))\n",
        "tokenizer.fit_on_texts(quotes)\n",
        "\n",
        "sequence = tokenizer.texts_to_sequences(quotes)\n",
        "sequence[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhBqHvbW5QRk",
        "outputId": "4894c53f-8a8d-4303-d0ff-e654a5d3e1aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "“the world as we have created it is a process of our thinking it cannot be changed without changing our thinking”\n",
            "“it is our choices harry that show what we truly are far more than our abilities”\n",
            "“there are only two ways to live your life one is as though nothing is a miracle the other is as though everything is a miracle”\n",
            "[713, 62, 29, 19, 16, 946, 10, 7, 5, 1156, 8, 70, 293, 10, 145, 12, 809, 104, 752, 70, 2461]\n",
            "[947, 7, 70, 871, 373, 9, 433, 21, 19, 465, 14, 294, 52, 54, 70, 3676]\n",
            "[1337, 14, 53, 201, 714, 3, 81, 15, 36, 37, 7, 29, 329, 93, 7, 5, 1157, 1, 101, 7, 29, 329, 126, 7, 5, 3677]\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "  print(quotes[i]);\n",
        "\n",
        "for i in range(3):\n",
        "  print(sequence[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3sXIL4a07851"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "Y =[]\n",
        "\n",
        "for i in range(len(quotes)):\n",
        "  for j in range(1,len(sequence[i])):\n",
        "    x_input = sequence[i][:j]\n",
        "    y_output = sequence[i][j];\n",
        "    X.append(x_input)\n",
        "    Y.append(y_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncVd3Nhd-8-R",
        "outputId": "b3ba862f-7197-4239-d788-e2b50f36fcad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85270"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "78Cfh-x5-_X9"
      },
      "outputs": [],
      "source": [
        "maxlen = max(len(x) for x in X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JpKx0oYTj3kU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGj0D5xC_gx_",
        "outputId": "c3fbd7c5-9984-42a4-f28b-5d5a82eb28a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "745"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "maxlen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cuKSzPr6_gSw"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "X_padded = pad_sequences(X, maxlen=maxlen, padding=\"pre\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c9eqIjc_936",
        "outputId": "cde63aac-7406-46bf-d868-ccd26a1c5fab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,    0,  713],\n",
              "       [   0,    0,    0, ...,    0,  713,   62],\n",
              "       [   0,    0,    0, ...,  713,   62,   29],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    9,   19, 1125],\n",
              "       [   0,    0,    0, ...,   19, 1125,    3],\n",
              "       [   0,    0,    0, ..., 1125,    3,  169]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X_padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MjmJImJ5ABqy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "Y_categorical = to_categorical(Y, num_classes=len(unique_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mz_Lt-6BEym",
        "outputId": "03b87db3-2a75-4de3-f4fc-820ab9f94670"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "Y_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-mrfdUcvFAo1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zmLIqYW9Fnz1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psu7oPUEH04c",
        "outputId": "e7ea0266-f680-4c49-a94a-7f9a59e9964c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "embedding_dim = 50\n",
        "rnn_units = 128\n",
        "vocab_size = len(unique_words)\n",
        "\n",
        "rnn_model = Sequential()\n",
        "rnn_model.add(Embedding(input_dim=len(unique_words), output_dim=embedding_dim, input_length=maxlen))\n",
        "rnn_model.add(SimpleRNN(units=rnn_units))\n",
        "rnn_model.add(Dense(units=vocab_size,activation=\"softmax\"))\n",
        "rnn_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "q-xN3Onsas51",
        "outputId": "e42ba020-52ca-4947-fe07-7f30de794792"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TAROE409J6fv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "27d6b32d-8dd1-4631-dd90-e61e133e3342"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3726939967.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history_rnn = rnn_model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mX_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_categorical\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_slicing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_validation_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/array_slicing.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[0;34m(arrays, validation_split)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m     \u001b[0msliceables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_sliceable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m     train_arrays = tree.map_structure(\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_at\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msliceables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/array_slicing.py\u001b[0m in \u001b[0;36mconvert_to_sliceable\u001b[0;34m(arrays, target_backend)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msliceable_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_single_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/tree/tree_api.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \"\"\"\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/tree/optree_impl.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mmap_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_with_check\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     return optree.tree_map(\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_is_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"keras\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optree/ops.py\u001b[0m in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreespec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_is_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/array_slicing.py\u001b[0m in \u001b[0;36mconvert_single_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcast_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliceable_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# Step 3. Apply target backend specific logic and optimizations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/array_slicing.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(cls, x, dtype)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcast\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \"\"\"\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "history_rnn = rnn_model.fit(\n",
        "    X_padded, Y_categorical,epochs=10, batch_size=32,validation_split=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = Sequential()\n",
        "lstm_model.add(\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen),\n",
        ")\n",
        "lstm_model.add(LSTM(units=rnn_units))\n",
        "lstm_model.add(Dense(units=vocab_size, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "JRvJoP99Wdan"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ip1MGcPhioZs"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "KFk8oq4-ixWT",
        "outputId": "847b8957-82f6-4267-9ed7-8aab2789d12d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_history = lstm_model.fit(X_padded, Y_categorical, batch_size=40, epochs=100, verbose=1, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSR2TnA2jEq7",
        "outputId": "3c4a2551-6e0b-4cd1-bf16-d9e1e0f6b52c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 32ms/step - accuracy: 0.0391 - loss: 6.8899 - val_accuracy: 0.0646 - val_loss: 6.5054\n",
            "Epoch 2/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.0770 - loss: 6.0965 - val_accuracy: 0.0907 - val_loss: 6.3939\n",
            "Epoch 3/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.1030 - loss: 5.6881 - val_accuracy: 0.1037 - val_loss: 6.3572\n",
            "Epoch 4/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.1235 - loss: 5.3581 - val_accuracy: 0.1109 - val_loss: 6.4005\n",
            "Epoch 5/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 33ms/step - accuracy: 0.1407 - loss: 5.0543 - val_accuracy: 0.1166 - val_loss: 6.4847\n",
            "Epoch 6/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.1564 - loss: 4.7838 - val_accuracy: 0.1149 - val_loss: 6.6012\n",
            "Epoch 7/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.1743 - loss: 4.5093 - val_accuracy: 0.1150 - val_loss: 6.7169\n",
            "Epoch 8/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.1963 - loss: 4.2552 - val_accuracy: 0.1150 - val_loss: 6.8535\n",
            "Epoch 9/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 32ms/step - accuracy: 0.2198 - loss: 4.0141 - val_accuracy: 0.1109 - val_loss: 6.9684\n",
            "Epoch 10/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.2543 - loss: 3.7885 - val_accuracy: 0.1104 - val_loss: 7.0948\n",
            "Epoch 11/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 31ms/step - accuracy: 0.2831 - loss: 3.5873 - val_accuracy: 0.1107 - val_loss: 7.2230\n",
            "Epoch 12/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.3156 - loss: 3.3832 - val_accuracy: 0.1094 - val_loss: 7.3372\n",
            "Epoch 13/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.3376 - loss: 3.2291 - val_accuracy: 0.1033 - val_loss: 7.4550\n",
            "Epoch 14/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 31ms/step - accuracy: 0.3664 - loss: 3.0693 - val_accuracy: 0.1021 - val_loss: 7.5778\n",
            "Epoch 15/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 32ms/step - accuracy: 0.3899 - loss: 2.9371 - val_accuracy: 0.0979 - val_loss: 7.6764\n",
            "Epoch 16/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.4152 - loss: 2.8018 - val_accuracy: 0.1011 - val_loss: 7.7882\n",
            "Epoch 17/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.4345 - loss: 2.6793 - val_accuracy: 0.0979 - val_loss: 7.8902\n",
            "Epoch 18/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.4521 - loss: 2.5774 - val_accuracy: 0.0957 - val_loss: 7.9861\n",
            "Epoch 19/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.4719 - loss: 2.4742 - val_accuracy: 0.0966 - val_loss: 8.1142\n",
            "Epoch 20/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 32ms/step - accuracy: 0.4870 - loss: 2.3758 - val_accuracy: 0.0945 - val_loss: 8.1968\n",
            "Epoch 21/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.5089 - loss: 2.2707 - val_accuracy: 0.0897 - val_loss: 8.3126\n",
            "Epoch 22/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.5231 - loss: 2.1991 - val_accuracy: 0.0909 - val_loss: 8.4064\n",
            "Epoch 23/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 33ms/step - accuracy: 0.5396 - loss: 2.1205 - val_accuracy: 0.0911 - val_loss: 8.5087\n",
            "Epoch 24/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.5548 - loss: 2.0383 - val_accuracy: 0.0889 - val_loss: 8.6276\n",
            "Epoch 25/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.5707 - loss: 1.9650 - val_accuracy: 0.0907 - val_loss: 8.7352\n",
            "Epoch 26/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.5849 - loss: 1.8945 - val_accuracy: 0.0892 - val_loss: 8.8247\n",
            "Epoch 27/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.5987 - loss: 1.8279 - val_accuracy: 0.0892 - val_loss: 8.9529\n",
            "Epoch 28/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.6092 - loss: 1.7753 - val_accuracy: 0.0868 - val_loss: 9.0396\n",
            "Epoch 29/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.6205 - loss: 1.7255 - val_accuracy: 0.0851 - val_loss: 9.1285\n",
            "Epoch 30/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.6333 - loss: 1.6644 - val_accuracy: 0.0850 - val_loss: 9.2343\n",
            "Epoch 31/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.6403 - loss: 1.6137 - val_accuracy: 0.0848 - val_loss: 9.3312\n",
            "Epoch 32/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.6517 - loss: 1.5663 - val_accuracy: 0.0831 - val_loss: 9.4369\n",
            "Epoch 33/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.6637 - loss: 1.5212 - val_accuracy: 0.0815 - val_loss: 9.4857\n",
            "Epoch 34/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.6737 - loss: 1.4737 - val_accuracy: 0.0812 - val_loss: 9.6291\n",
            "Epoch 35/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.6850 - loss: 1.4226 - val_accuracy: 0.0800 - val_loss: 9.7406\n",
            "Epoch 36/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.6912 - loss: 1.3883 - val_accuracy: 0.0799 - val_loss: 9.8477\n",
            "Epoch 37/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 33ms/step - accuracy: 0.6951 - loss: 1.3586 - val_accuracy: 0.0792 - val_loss: 9.9114\n",
            "Epoch 38/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7011 - loss: 1.3292 - val_accuracy: 0.0781 - val_loss: 9.9897\n",
            "Epoch 39/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 32ms/step - accuracy: 0.7119 - loss: 1.2851 - val_accuracy: 0.0755 - val_loss: 10.0995\n",
            "Epoch 40/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7212 - loss: 1.2485 - val_accuracy: 0.0778 - val_loss: 10.1758\n",
            "Epoch 41/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7287 - loss: 1.2172 - val_accuracy: 0.0781 - val_loss: 10.2790\n",
            "Epoch 42/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7301 - loss: 1.2008 - val_accuracy: 0.0736 - val_loss: 10.4237\n",
            "Epoch 43/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7360 - loss: 1.1711 - val_accuracy: 0.0763 - val_loss: 10.4870\n",
            "Epoch 44/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7455 - loss: 1.1272 - val_accuracy: 0.0749 - val_loss: 10.5673\n",
            "Epoch 45/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7495 - loss: 1.1211 - val_accuracy: 0.0728 - val_loss: 10.6438\n",
            "Epoch 46/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7584 - loss: 1.0814 - val_accuracy: 0.0755 - val_loss: 10.7628\n",
            "Epoch 47/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 32ms/step - accuracy: 0.7624 - loss: 1.0541 - val_accuracy: 0.0751 - val_loss: 10.8064\n",
            "Epoch 48/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7691 - loss: 1.0338 - val_accuracy: 0.0712 - val_loss: 10.8859\n",
            "Epoch 49/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7706 - loss: 1.0136 - val_accuracy: 0.0766 - val_loss: 10.9536\n",
            "Epoch 50/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7740 - loss: 0.9935 - val_accuracy: 0.0756 - val_loss: 11.0387\n",
            "Epoch 51/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7819 - loss: 0.9740 - val_accuracy: 0.0740 - val_loss: 11.1401\n",
            "Epoch 52/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7843 - loss: 0.9612 - val_accuracy: 0.0756 - val_loss: 11.2121\n",
            "Epoch 53/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.7886 - loss: 0.9347 - val_accuracy: 0.0744 - val_loss: 11.3232\n",
            "Epoch 54/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7914 - loss: 0.9095 - val_accuracy: 0.0727 - val_loss: 11.3571\n",
            "Epoch 55/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.7988 - loss: 0.8946 - val_accuracy: 0.0753 - val_loss: 11.4742\n",
            "Epoch 56/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.8006 - loss: 0.8796 - val_accuracy: 0.0733 - val_loss: 11.5385\n",
            "Epoch 57/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.8051 - loss: 0.8660 - val_accuracy: 0.0728 - val_loss: 11.6418\n",
            "Epoch 58/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8064 - loss: 0.8502 - val_accuracy: 0.0686 - val_loss: 11.6831\n",
            "Epoch 59/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8119 - loss: 0.8284 - val_accuracy: 0.0710 - val_loss: 11.7845\n",
            "Epoch 60/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8150 - loss: 0.8171 - val_accuracy: 0.0729 - val_loss: 11.8483\n",
            "Epoch 61/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8172 - loss: 0.8035 - val_accuracy: 0.0715 - val_loss: 11.9295\n",
            "Epoch 62/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 32ms/step - accuracy: 0.8197 - loss: 0.7898 - val_accuracy: 0.0693 - val_loss: 12.0069\n",
            "Epoch 63/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 32ms/step - accuracy: 0.8238 - loss: 0.7800 - val_accuracy: 0.0724 - val_loss: 12.0732\n",
            "Epoch 64/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.8253 - loss: 0.7700 - val_accuracy: 0.0678 - val_loss: 12.1412\n",
            "Epoch 65/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8261 - loss: 0.7569 - val_accuracy: 0.0694 - val_loss: 12.2107\n",
            "Epoch 66/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8320 - loss: 0.7345 - val_accuracy: 0.0680 - val_loss: 12.2892\n",
            "Epoch 67/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8324 - loss: 0.7357 - val_accuracy: 0.0704 - val_loss: 12.3422\n",
            "Epoch 68/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8320 - loss: 0.7328 - val_accuracy: 0.0706 - val_loss: 12.4440\n",
            "Epoch 69/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8394 - loss: 0.7078 - val_accuracy: 0.0681 - val_loss: 12.4918\n",
            "Epoch 70/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.8411 - loss: 0.6983 - val_accuracy: 0.0678 - val_loss: 12.5875\n",
            "Epoch 71/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8405 - loss: 0.7017 - val_accuracy: 0.0659 - val_loss: 12.6128\n",
            "Epoch 72/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.8417 - loss: 0.6893 - val_accuracy: 0.0705 - val_loss: 12.6896\n",
            "Epoch 73/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 32ms/step - accuracy: 0.8439 - loss: 0.6787 - val_accuracy: 0.0698 - val_loss: 12.7614\n",
            "Epoch 74/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.8464 - loss: 0.6735 - val_accuracy: 0.0676 - val_loss: 12.7938\n",
            "Epoch 75/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8474 - loss: 0.6646 - val_accuracy: 0.0679 - val_loss: 12.8846\n",
            "Epoch 76/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8498 - loss: 0.6558 - val_accuracy: 0.0654 - val_loss: 12.9303\n",
            "Epoch 77/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 33ms/step - accuracy: 0.8539 - loss: 0.6389 - val_accuracy: 0.0676 - val_loss: 12.9845\n",
            "Epoch 78/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8507 - loss: 0.6441 - val_accuracy: 0.0676 - val_loss: 13.0459\n",
            "Epoch 79/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.8576 - loss: 0.6193 - val_accuracy: 0.0674 - val_loss: 13.0862\n",
            "Epoch 80/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 33ms/step - accuracy: 0.8546 - loss: 0.6265 - val_accuracy: 0.0691 - val_loss: 13.1674\n",
            "Epoch 81/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 33ms/step - accuracy: 0.8581 - loss: 0.6119 - val_accuracy: 0.0688 - val_loss: 13.2298\n",
            "Epoch 82/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8610 - loss: 0.6037 - val_accuracy: 0.0672 - val_loss: 13.2778\n",
            "Epoch 83/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8621 - loss: 0.6010 - val_accuracy: 0.0663 - val_loss: 13.3460\n",
            "Epoch 84/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8638 - loss: 0.5888 - val_accuracy: 0.0683 - val_loss: 13.4198\n",
            "Epoch 85/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 33ms/step - accuracy: 0.8638 - loss: 0.5907 - val_accuracy: 0.0649 - val_loss: 13.4544\n",
            "Epoch 86/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8640 - loss: 0.5868 - val_accuracy: 0.0674 - val_loss: 13.5405\n",
            "Epoch 87/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8628 - loss: 0.5896 - val_accuracy: 0.0670 - val_loss: 13.5625\n",
            "Epoch 88/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.8434 - loss: 0.6784 - val_accuracy: 0.0685 - val_loss: 13.5760\n",
            "Epoch 89/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 32ms/step - accuracy: 0.8472 - loss: 0.6512 - val_accuracy: 0.0666 - val_loss: 13.6222\n",
            "Epoch 90/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 32ms/step - accuracy: 0.8555 - loss: 0.6132 - val_accuracy: 0.0663 - val_loss: 13.6301\n",
            "Epoch 91/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 33ms/step - accuracy: 0.8685 - loss: 0.5692 - val_accuracy: 0.0677 - val_loss: 13.6907\n",
            "Epoch 92/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8588 - loss: 0.5953 - val_accuracy: 0.0647 - val_loss: 13.6781\n",
            "Epoch 93/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8563 - loss: 0.5993 - val_accuracy: 0.0650 - val_loss: 13.7700\n",
            "Epoch 94/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8808 - loss: 0.5241 - val_accuracy: 0.0668 - val_loss: 13.8217\n",
            "Epoch 95/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8735 - loss: 0.5401 - val_accuracy: 0.0684 - val_loss: 13.8383\n",
            "Epoch 96/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 32ms/step - accuracy: 0.8703 - loss: 0.5505 - val_accuracy: 0.0670 - val_loss: 13.9361\n",
            "Epoch 97/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8596 - loss: 0.5757 - val_accuracy: 0.0664 - val_loss: 13.9511\n",
            "Epoch 98/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8716 - loss: 0.5467 - val_accuracy: 0.0676 - val_loss: 13.9934\n",
            "Epoch 99/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8785 - loss: 0.5170 - val_accuracy: 0.0659 - val_loss: 14.0173\n",
            "Epoch 100/100\n",
            "\u001b[1m1919/1919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 32ms/step - accuracy: 0.8702 - loss: 0.5424 - val_accuracy: 0.0647 - val_loss: 14.1310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.save(\"lstm_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2bp70aojd-O",
        "outputId": "43a4bb7e-46fe-45dd-c1d8-aced6deffa08"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word = {}\n",
        "\n",
        "for word, index in tokenizer.word_index.items():\n",
        "  index_to_word[index] = word"
      ],
      "metadata": {
        "id": "dzNF0iOU955F"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxSyaaq_-R5p",
        "outputId": "08ab902b-0594-4aa1-d232-d06232489f41"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'the',\n",
              " 2: 'you',\n",
              " 3: 'to',\n",
              " 4: 'and',\n",
              " 5: 'a',\n",
              " 6: 'i',\n",
              " 7: 'is',\n",
              " 8: 'of',\n",
              " 9: 'that',\n",
              " 10: 'it',\n",
              " 11: 'in',\n",
              " 12: 'be',\n",
              " 13: 'not',\n",
              " 14: 'are',\n",
              " 15: 'your',\n",
              " 16: 'have',\n",
              " 17: 'for',\n",
              " 18: 'but',\n",
              " 19: 'we',\n",
              " 20: 'if',\n",
              " 21: 'what',\n",
              " 22: 'with',\n",
              " 23: 'all',\n",
              " 24: 'love',\n",
              " 25: 'can',\n",
              " 26: 'my',\n",
              " 27: 'when',\n",
              " 28: 'will',\n",
              " 29: 'as',\n",
              " 30: 'who',\n",
              " 31: 'do',\n",
              " 32: 'or',\n",
              " 33: 'me',\n",
              " 34: 'he',\n",
              " 35: 'they',\n",
              " 36: 'life',\n",
              " 37: 'one',\n",
              " 38: 'was',\n",
              " 39: 'like',\n",
              " 40: 'there',\n",
              " 41: 'people',\n",
              " 42: 'on',\n",
              " 43: 'its',\n",
              " 44: 'at',\n",
              " 45: 'so',\n",
              " 46: 'never',\n",
              " 47: 'no',\n",
              " 48: 'them',\n",
              " 49: 'dont',\n",
              " 50: 'know',\n",
              " 51: 'just',\n",
              " 52: 'more',\n",
              " 53: 'only',\n",
              " 54: 'than',\n",
              " 55: 'because',\n",
              " 56: 'this',\n",
              " 57: 'want',\n",
              " 58: 'up',\n",
              " 59: 'how',\n",
              " 60: 'his',\n",
              " 61: 'things',\n",
              " 62: 'world',\n",
              " 63: 'by',\n",
              " 64: 'think',\n",
              " 65: 'make',\n",
              " 66: 'about',\n",
              " 67: 'time',\n",
              " 68: 'from',\n",
              " 69: 'always',\n",
              " 70: 'our',\n",
              " 71: 'an',\n",
              " 72: 'out',\n",
              " 73: 'us',\n",
              " 74: 'good',\n",
              " 75: 'said',\n",
              " 76: 'she',\n",
              " 77: 'her',\n",
              " 78: 'way',\n",
              " 79: 'go',\n",
              " 80: 'am',\n",
              " 81: 'live',\n",
              " 82: 'has',\n",
              " 83: 'something',\n",
              " 84: 'see',\n",
              " 85: 'too',\n",
              " 86: 'then',\n",
              " 87: 'every',\n",
              " 88: 'were',\n",
              " 89: 'some',\n",
              " 90: 'man',\n",
              " 91: 'thing',\n",
              " 92: 'heart',\n",
              " 93: 'nothing',\n",
              " 94: 'get',\n",
              " 95: 'him',\n",
              " 96: 'youre',\n",
              " 97: 'would',\n",
              " 98: 'those',\n",
              " 99: 'their',\n",
              " 100: 'yourself',\n",
              " 101: 'other',\n",
              " 102: 'let',\n",
              " 103: 'into',\n",
              " 104: 'without',\n",
              " 105: 'much',\n",
              " 106: 'im',\n",
              " 107: 'could',\n",
              " 108: 'had',\n",
              " 109: 'someone',\n",
              " 110: 'ever',\n",
              " 111: 'day',\n",
              " 112: 'even',\n",
              " 113: 'find',\n",
              " 114: 'books',\n",
              " 115: 'right',\n",
              " 116: 'person',\n",
              " 117: 'most',\n",
              " 118: 'say',\n",
              " 119: 'must',\n",
              " 120: 'which',\n",
              " 121: 'been',\n",
              " 122: 'own',\n",
              " 123: 'sometimes',\n",
              " 124: 'read',\n",
              " 125: 'should',\n",
              " 126: 'everything',\n",
              " 127: 'believe',\n",
              " 128: 'being',\n",
              " 129: 'really',\n",
              " 130: 'going',\n",
              " 131: 'feel',\n",
              " 132: 'come',\n",
              " 133: 'give',\n",
              " 134: 'may',\n",
              " 135: 'where',\n",
              " 136: 'book',\n",
              " 137: 'thats',\n",
              " 138: 'tell',\n",
              " 139: 'little',\n",
              " 140: 'cant',\n",
              " 141: 'back',\n",
              " 142: 'words',\n",
              " 143: 'over',\n",
              " 144: 'better',\n",
              " 145: 'cannot',\n",
              " 146: 'through',\n",
              " 147: 'now',\n",
              " 148: 'any',\n",
              " 149: 'enough',\n",
              " 150: 'does',\n",
              " 151: 'great',\n",
              " 152: 'god',\n",
              " 153: 'look',\n",
              " 154: 'anything',\n",
              " 155: 'change',\n",
              " 156: 'another',\n",
              " 157: 'many',\n",
              " 158: 'remember',\n",
              " 159: 'best',\n",
              " 160: 'down',\n",
              " 161: 'true',\n",
              " 162: 'still',\n",
              " 163: 'did',\n",
              " 164: 'need',\n",
              " 165: 'mind',\n",
              " 166: 'soul',\n",
              " 167: 'well',\n",
              " 168: 'until',\n",
              " 169: 'each',\n",
              " 170: 'again',\n",
              " 171: 'else',\n",
              " 172: 'why',\n",
              " 173: 'long',\n",
              " 174: 'truth',\n",
              " 175: 'loved',\n",
              " 176: 'keep',\n",
              " 177: 'very',\n",
              " 178: 'first',\n",
              " 179: 'moment',\n",
              " 180: 'woman',\n",
              " 181: 'matter',\n",
              " 182: 'doesnt',\n",
              " 183: 'before',\n",
              " 184: 'men',\n",
              " 185: 'others',\n",
              " 186: 'once',\n",
              " 187: 'human',\n",
              " 188: 'fear',\n",
              " 189: 'end',\n",
              " 190: 'around',\n",
              " 191: 'ive',\n",
              " 192: 'beautiful',\n",
              " 193: 'happy',\n",
              " 194: 'kind',\n",
              " 195: 'don’t',\n",
              " 196: 'die',\n",
              " 197: 'girl',\n",
              " 198: 'happiness',\n",
              " 199: 'made',\n",
              " 200: 'take',\n",
              " 201: 'two',\n",
              " 202: 'become',\n",
              " 203: 'learn',\n",
              " 204: 'myself',\n",
              " 205: 'theres',\n",
              " 206: 'got',\n",
              " 207: 'hope',\n",
              " 208: 'part',\n",
              " 209: 'same',\n",
              " 210: 'alone',\n",
              " 211: 'pain',\n",
              " 212: 'friends',\n",
              " 213: 'makes',\n",
              " 214: 'death',\n",
              " 215: 'real',\n",
              " 216: 'friend',\n",
              " 217: 'inside',\n",
              " 218: 'thought',\n",
              " 219: 'after',\n",
              " 220: 'years',\n",
              " 221: 'here',\n",
              " 222: 'eyes',\n",
              " 223: 'wrong',\n",
              " 224: 'understand',\n",
              " 225: 'loves',\n",
              " 226: 'lives',\n",
              " 227: 'reading',\n",
              " 228: 'fall',\n",
              " 229: 'new',\n",
              " 230: 'light',\n",
              " 231: 'forever',\n",
              " 232: 'while',\n",
              " 233: 'dream',\n",
              " 234: 'ones',\n",
              " 235: 'everyone',\n",
              " 236: 'living',\n",
              " 237: 'youll',\n",
              " 238: 'bad',\n",
              " 239: 'lose',\n",
              " 240: 'away',\n",
              " 241: 'forget',\n",
              " 242: 'shall',\n",
              " 243: 'hard',\n",
              " 244: 'upon',\n",
              " 245: 'between',\n",
              " 246: 'face',\n",
              " 247: 'stop',\n",
              " 248: 'write',\n",
              " 249: 'dreams',\n",
              " 250: 'off',\n",
              " 251: 'future',\n",
              " 252: 'whole',\n",
              " 253: 'might',\n",
              " 254: 'maybe',\n",
              " 255: 'ourselves',\n",
              " 256: 'hell',\n",
              " 257: 'looking',\n",
              " 258: 'stars',\n",
              " 259: 'wanted',\n",
              " 260: 'trying',\n",
              " 261: 'old',\n",
              " 262: 'last',\n",
              " 263: 'isnt',\n",
              " 264: 'courage',\n",
              " 265: 'try',\n",
              " 266: 'mean',\n",
              " 267: 'together',\n",
              " 268: 'doing',\n",
              " 269: 'place',\n",
              " 270: 'less',\n",
              " 271: 'stay',\n",
              " 272: 'theyre',\n",
              " 273: 'hate',\n",
              " 274: 'knows',\n",
              " 275: 'earth',\n",
              " 276: 'put',\n",
              " 277: 'felt',\n",
              " 278: 'times',\n",
              " 279: 'rather',\n",
              " 280: 'often',\n",
              " 281: 'work',\n",
              " 282: 'night',\n",
              " 283: 'trust',\n",
              " 284: 'grow',\n",
              " 285: 'walk',\n",
              " 286: 'says',\n",
              " 287: 'saying',\n",
              " 288: 'anyone',\n",
              " 289: 'smile',\n",
              " 290: 'hurt',\n",
              " 291: 'story',\n",
              " 292: 'listen',\n",
              " 293: 'thinking',\n",
              " 294: 'far',\n",
              " 295: 'laugh',\n",
              " 296: 'small',\n",
              " 297: 'having',\n",
              " 298: 'reality',\n",
              " 299: 'means',\n",
              " 300: 'women',\n",
              " 301: 'sad',\n",
              " 302: 'leave',\n",
              " 303: 'these',\n",
              " 304: 'head',\n",
              " 305: 'music',\n",
              " 306: 'i’m',\n",
              " 307: 'youve',\n",
              " 308: 'it’s',\n",
              " 309: 'important',\n",
              " 310: 'somebody',\n",
              " 311: 'against',\n",
              " 312: 'feeling',\n",
              " 313: 'beauty',\n",
              " 314: 'stand',\n",
              " 315: 'hand',\n",
              " 316: 'done',\n",
              " 317: 'reason',\n",
              " 318: 'universe',\n",
              " 319: 'didnt',\n",
              " 320: 'fire',\n",
              " 321: 'told',\n",
              " 322: 'strong',\n",
              " 323: 'happens',\n",
              " 324: 'sure',\n",
              " 325: 'talk',\n",
              " 326: 'word',\n",
              " 327: 'himself',\n",
              " 328: 'full',\n",
              " 329: 'though',\n",
              " 330: 'gone',\n",
              " 331: 'worth',\n",
              " 332: 'point',\n",
              " 333: 'door',\n",
              " 334: 'broken',\n",
              " 335: 'dark',\n",
              " 336: 'sit',\n",
              " 337: 'wish',\n",
              " 338: 'happen',\n",
              " 339: 'you’re',\n",
              " 340: 'least',\n",
              " 341: 'past',\n",
              " 342: 'comes',\n",
              " 343: 'hold',\n",
              " 344: 'takes',\n",
              " 345: 'perfect',\n",
              " 346: 'stupid',\n",
              " 347: 'children',\n",
              " 348: 'start',\n",
              " 349: 'experience',\n",
              " 350: 'power',\n",
              " 351: 'yet',\n",
              " 352: 'asked',\n",
              " 353: 'realize',\n",
              " 354: 'making',\n",
              " 355: 'behind',\n",
              " 356: 'left',\n",
              " 357: 'wants',\n",
              " 358: 'choose',\n",
              " 359: 'lot',\n",
              " 360: 'whatever',\n",
              " 361: 'lost',\n",
              " 362: 'looked',\n",
              " 363: 'wont',\n",
              " 364: 'knowing',\n",
              " 365: 'few',\n",
              " 366: 'lie',\n",
              " 367: 'different',\n",
              " 368: 'hear',\n",
              " 369: 'afraid',\n",
              " 370: 'jace',\n",
              " 371: 'ask',\n",
              " 372: 'home',\n",
              " 373: 'harry',\n",
              " 374: 'impossible',\n",
              " 375: 'lies',\n",
              " 376: 'open',\n",
              " 377: 'easy',\n",
              " 378: 'already',\n",
              " 379: 'three',\n",
              " 380: 'exist',\n",
              " 381: 'such',\n",
              " 382: 'possible',\n",
              " 383: 'use',\n",
              " 384: 'thoughts',\n",
              " 385: 'within',\n",
              " 386: 'days',\n",
              " 387: '—',\n",
              " 388: 'themselves',\n",
              " 389: 'also',\n",
              " 390: 'break',\n",
              " 391: 'mistakes',\n",
              " 392: 'loving',\n",
              " 393: 'alive',\n",
              " 394: 'next',\n",
              " 395: 'happened',\n",
              " 396: 'wait',\n",
              " 397: 'side',\n",
              " 398: 'both',\n",
              " 399: 'ill',\n",
              " 400: 'secret',\n",
              " 401: 'deep',\n",
              " 402: 'sleep',\n",
              " 403: 'silence',\n",
              " 404: 'either',\n",
              " 405: 'suffering',\n",
              " 406: 'tomorrow',\n",
              " 407: 'call',\n",
              " 408: 'strength',\n",
              " 409: 'help',\n",
              " 410: 'meant',\n",
              " 411: 'knew',\n",
              " 412: 'speak',\n",
              " 413: 'itself',\n",
              " 414: 'seen',\n",
              " 415: 'found',\n",
              " 416: 'pretty',\n",
              " 417: 'half',\n",
              " 418: 'goes',\n",
              " 419: 'high',\n",
              " 420: 'lived',\n",
              " 421: 'darkness',\n",
              " 422: 'yours',\n",
              " 423: 'choice',\n",
              " 424: 'forgive',\n",
              " 425: 'respect',\n",
              " 426: 'young',\n",
              " 427: 'simple',\n",
              " 428: 'close',\n",
              " 429: 'kill',\n",
              " 430: 'beginning',\n",
              " 431: 'whats',\n",
              " 432: 'perhaps',\n",
              " 433: 'show',\n",
              " 434: 'success',\n",
              " 435: 'arent',\n",
              " 436: 'mad',\n",
              " 437: 'friendship',\n",
              " 438: 'thousand',\n",
              " 439: 'crazy',\n",
              " 440: 'house',\n",
              " 441: 'nobody',\n",
              " 442: 'history',\n",
              " 443: 'able',\n",
              " 444: 'set',\n",
              " 445: 'meet',\n",
              " 446: 'hands',\n",
              " 447: 'rest',\n",
              " 448: 'answer',\n",
              " 449: 'id',\n",
              " 450: 'voice',\n",
              " 451: 'dare',\n",
              " 452: 'second',\n",
              " 453: 'expect',\n",
              " 454: 'war',\n",
              " 455: 'free',\n",
              " 456: 'room',\n",
              " 457: 'seems',\n",
              " 458: 'somewhere',\n",
              " 459: 'care',\n",
              " 460: 'couldnt',\n",
              " 461: 'fight',\n",
              " 462: 'known',\n",
              " 463: 'lonely',\n",
              " 464: 'family',\n",
              " 465: 'truly',\n",
              " 466: 'decide',\n",
              " 467: 'year',\n",
              " 468: 'black',\n",
              " 469: 'unless',\n",
              " 470: 'begin',\n",
              " 471: 'turn',\n",
              " 472: 'sun',\n",
              " 473: 'body',\n",
              " 474: 'today',\n",
              " 475: 'enjoy',\n",
              " 476: 'child',\n",
              " 477: 'fact',\n",
              " 478: 'worse',\n",
              " 479: 'yes',\n",
              " 480: 'freedom',\n",
              " 481: 'mother',\n",
              " 482: 'actually',\n",
              " 483: 'course',\n",
              " 484: 'born',\n",
              " 485: 'seem',\n",
              " 486: 'difference',\n",
              " 487: 'dead',\n",
              " 488: 'taste',\n",
              " 489: 'everybody',\n",
              " 490: 'peace',\n",
              " 491: 'took',\n",
              " 492: '–',\n",
              " 493: 'stories',\n",
              " 494: 'loneliness',\n",
              " 495: 'art',\n",
              " 496: 'imagination',\n",
              " 497: 'wise',\n",
              " 498: 'big',\n",
              " 499: 'question',\n",
              " 500: 'boy',\n",
              " 501: 'learned',\n",
              " 502: 'single',\n",
              " 503: 'completely',\n",
              " 504: 'water',\n",
              " 505: 'knowledge',\n",
              " 506: 'gives',\n",
              " 507: 'hes',\n",
              " 508: 'wisdom',\n",
              " 509: 'desire',\n",
              " 510: 'carry',\n",
              " 511: 'gets',\n",
              " 512: 'sea',\n",
              " 513: 'waste',\n",
              " 514: 'bear',\n",
              " 515: 'father',\n",
              " 516: 'girls',\n",
              " 517: 'act',\n",
              " 518: 'fool',\n",
              " 519: 'persons',\n",
              " 520: 'control',\n",
              " 521: 'finally',\n",
              " 522: 'apart',\n",
              " 523: 'special',\n",
              " 524: 'quite',\n",
              " 525: 'stronger',\n",
              " 526: 'imagine',\n",
              " 527: 'name',\n",
              " 528: 'hurts',\n",
              " 529: 'minds',\n",
              " 530: 'under',\n",
              " 531: 'teach',\n",
              " 532: 'school',\n",
              " 533: 'nice',\n",
              " 534: 'touch',\n",
              " 535: 'wake',\n",
              " 536: 'tree',\n",
              " 537: 'morning',\n",
              " 538: 'mine',\n",
              " 539: 'ten',\n",
              " 540: 'called',\n",
              " 541: 'came',\n",
              " 542: 'seek',\n",
              " 543: 'weve',\n",
              " 544: 'sense',\n",
              " 545: 'getting',\n",
              " 546: 'kiss',\n",
              " 547: 'writing',\n",
              " 548: 'needs',\n",
              " 549: 'deserve',\n",
              " 550: 'dance',\n",
              " 551: 'front',\n",
              " 552: 'greatest',\n",
              " 553: 'memories',\n",
              " 554: 'sky',\n",
              " 555: 'joy',\n",
              " 556: 'feet',\n",
              " 557: 'used',\n",
              " 558: 'nor',\n",
              " 559: 'value',\n",
              " 560: 'age',\n",
              " 561: 'longer',\n",
              " 562: 'wouldnt',\n",
              " 563: 'certain',\n",
              " 564: 'okay',\n",
              " 565: 'spend',\n",
              " 566: 'run',\n",
              " 567: 'clary',\n",
              " 568: 'arms',\n",
              " 569: 'merely',\n",
              " 570: 'hearts',\n",
              " 571: 'blood',\n",
              " 572: 'short',\n",
              " 573: 'met',\n",
              " 574: 'shes',\n",
              " 575: 'miss',\n",
              " 576: 'simply',\n",
              " 577: 'thinks',\n",
              " 578: 'intelligent',\n",
              " 579: 'oh',\n",
              " 580: 'wrote',\n",
              " 581: 'brave',\n",
              " 582: 'whom',\n",
              " 583: 'written',\n",
              " 584: 'can’t',\n",
              " 585: 'cry',\n",
              " 586: 'feelings',\n",
              " 587: 'storm',\n",
              " 588: 'anybody',\n",
              " 589: 'poetry',\n",
              " 590: 'wonder',\n",
              " 591: 'powerful',\n",
              " 592: 'magic',\n",
              " 593: 'gave',\n",
              " 594: 'guy',\n",
              " 595: 'step',\n",
              " 596: 'burn',\n",
              " 597: 'moon',\n",
              " 598: 'escape',\n",
              " 599: 'passion',\n",
              " 600: 'trees',\n",
              " 601: 'pleasure',\n",
              " 602: 'matters',\n",
              " 603: 'fantasy',\n",
              " 604: 'necessary',\n",
              " 605: 'faith',\n",
              " 606: 'late',\n",
              " 607: 'leaves',\n",
              " 608: 'drink',\n",
              " 609: 'avoid',\n",
              " 610: 'above',\n",
              " 611: 'heard',\n",
              " 612: 'along',\n",
              " 613: 'travel',\n",
              " 614: 'infinite',\n",
              " 615: 'throw',\n",
              " 616: 'library',\n",
              " 617: 'questions',\n",
              " 618: 'looks',\n",
              " 619: 'usually',\n",
              " 620: 'holding',\n",
              " 621: 'youd',\n",
              " 622: 'instead',\n",
              " 623: 'poor',\n",
              " 624: 'memory',\n",
              " 625: 'hour',\n",
              " 626: 'grief',\n",
              " 627: 'meaning',\n",
              " 628: 'becomes',\n",
              " 629: 'hide',\n",
              " 630: 'saw',\n",
              " 631: 'weak',\n",
              " 632: 'falling',\n",
              " 633: 'sex',\n",
              " 634: 'almost',\n",
              " 635: 'play',\n",
              " 636: 'shut',\n",
              " 637: 'cool',\n",
              " 638: 'genius',\n",
              " 639: 'hot',\n",
              " 640: 'deal',\n",
              " 641: 'minute',\n",
              " 642: 'places',\n",
              " 643: 'dies',\n",
              " 644: 'probably',\n",
              " 645: 'coming',\n",
              " 646: 'painful',\n",
              " 647: 'skin',\n",
              " 648: 'heaven',\n",
              " 649: 'accept',\n",
              " 650: 'you’ve',\n",
              " 651: 'build',\n",
              " 652: 'song',\n",
              " 653: 'laughter',\n",
              " 654: 'didn’t',\n",
              " 655: 'bring',\n",
              " 656: 'wind',\n",
              " 657: 'remain',\n",
              " 658: 'none',\n",
              " 659: 'common',\n",
              " 660: 'move',\n",
              " 661: 'nature',\n",
              " 662: 'purpose',\n",
              " 663: 'money',\n",
              " 664: 'waiting',\n",
              " 665: 'except',\n",
              " 666: 'air',\n",
              " 667: 'kids',\n",
              " 668: 'beyond',\n",
              " 669: 'losing',\n",
              " 670: 'middle',\n",
              " 671: 'evil',\n",
              " 672: 'tears',\n",
              " 673: 'follow',\n",
              " 674: 'running',\n",
              " 675: 'went',\n",
              " 676: 'sweet',\n",
              " 677: 'bed',\n",
              " 678: 'gods',\n",
              " 679: 'they’re',\n",
              " 680: 'لا',\n",
              " 681: 'و',\n",
              " 682: 'absolutely',\n",
              " 683: 'fail',\n",
              " 684: 'asleep',\n",
              " 685: 'fairy',\n",
              " 686: 'tales',\n",
              " 687: 'large',\n",
              " 688: 'angel',\n",
              " 689: 'ready',\n",
              " 690: 'tried',\n",
              " 691: 'therefore',\n",
              " 692: 'worst',\n",
              " 693: 'mans',\n",
              " 694: 'forward',\n",
              " 695: 'wonderful',\n",
              " 696: 'worry',\n",
              " 697: 'that’s',\n",
              " 698: 'present',\n",
              " 699: 'forgotten',\n",
              " 700: 'space',\n",
              " 701: 'dying',\n",
              " 702: 'whether',\n",
              " 703: 'rain',\n",
              " 704: 'amazing',\n",
              " 705: 'road',\n",
              " 706: 'count',\n",
              " 707: 'kindness',\n",
              " 708: 'eat',\n",
              " 709: 'wasnt',\n",
              " 710: 'white',\n",
              " 711: 'reach',\n",
              " 712: 'mouth',\n",
              " 713: '“the',\n",
              " 714: 'ways',\n",
              " 715: '“i',\n",
              " 716: 'judge',\n",
              " 717: 'eye',\n",
              " 718: 'sin',\n",
              " 719: 'soon',\n",
              " 720: 'spirit',\n",
              " 721: 'across',\n",
              " 722: 'lord',\n",
              " 723: 'terrible',\n",
              " 724: 'taken',\n",
              " 725: 'silent',\n",
              " 726: 'outside',\n",
              " 727: 'greater',\n",
              " 728: 'idea',\n",
              " 729: 'humans',\n",
              " 730: 'moving',\n",
              " 731: 'hours',\n",
              " 732: 'strange',\n",
              " 733: 'education',\n",
              " 734: 'sight',\n",
              " 735: 'learning',\n",
              " 736: 'sing',\n",
              " 737: 'begins',\n",
              " 738: 'fun',\n",
              " 739: 'fighting',\n",
              " 740: 'religion',\n",
              " 741: 'form',\n",
              " 742: 'paper',\n",
              " 743: 'crying',\n",
              " 744: 'piece',\n",
              " 745: 'window',\n",
              " 746: 'among',\n",
              " 747: 'leaving',\n",
              " 748: 'cut',\n",
              " 749: 'toward',\n",
              " 750: 'moments',\n",
              " 751: 'songs',\n",
              " 752: 'changing',\n",
              " 753: 'madness',\n",
              " 754: 'mess',\n",
              " 755: 'enemies',\n",
              " 756: 'needed',\n",
              " 757: 'unhappy',\n",
              " 758: 'chest',\n",
              " 759: 'angry',\n",
              " 760: 'problem',\n",
              " 761: 'order',\n",
              " 762: 'safe',\n",
              " 763: 'troubles',\n",
              " 764: 'trouble',\n",
              " 765: 'whenever',\n",
              " 766: 'someday',\n",
              " 767: 'mistake',\n",
              " 768: 'path',\n",
              " 769: 'difficult',\n",
              " 770: 'discover',\n",
              " 771: 'share',\n",
              " 772: 'blue',\n",
              " 773: 'fell',\n",
              " 774: 'please',\n",
              " 775: 'interesting',\n",
              " 776: 'figure',\n",
              " 777: 'failure',\n",
              " 778: 'hundred',\n",
              " 779: 'wounds',\n",
              " 780: 'given',\n",
              " 781: 'fly',\n",
              " 782: 'turned',\n",
              " 783: 'pretend',\n",
              " 784: 'telling',\n",
              " 785: 'giving',\n",
              " 786: 'stood',\n",
              " 787: 'watch',\n",
              " 788: 'glass',\n",
              " 789: 'summer',\n",
              " 790: 'hates',\n",
              " 791: 'food',\n",
              " 792: 'lips',\n",
              " 793: 'protect',\n",
              " 794: 'started',\n",
              " 795: 'havent',\n",
              " 796: 'ability',\n",
              " 797: 'easier',\n",
              " 798: 'ideas',\n",
              " 799: 'rare',\n",
              " 800: 'kissed',\n",
              " 801: 'fill',\n",
              " 802: 'opinion',\n",
              " 803: 'instant',\n",
              " 804: 'soft',\n",
              " 805: 'depends',\n",
              " 806: 'هو',\n",
              " 807: 'sort',\n",
              " 808: 'أن',\n",
              " 809: 'changed',\n",
              " 810: 'tea',\n",
              " 811: 'anyway',\n",
              " 812: 'baby',\n",
              " 813: 'smiling',\n",
              " 814: 'brain',\n",
              " 815: 'opposite',\n",
              " 816: 'indifference',\n",
              " 817: 'problems',\n",
              " 818: 'case',\n",
              " 819: 'cup',\n",
              " 820: 'attempt',\n",
              " 821: 'doubt',\n",
              " 822: 'ahead',\n",
              " 823: 'flower',\n",
              " 824: 'characters',\n",
              " 825: 'rules',\n",
              " 826: 'chance',\n",
              " 827: 'boring',\n",
              " 828: 'dragons',\n",
              " 829: 'risk',\n",
              " 830: 'gift',\n",
              " 831: 'deeply',\n",
              " 832: 'adventure',\n",
              " 833: 'walls',\n",
              " 834: 'guess',\n",
              " 835: 'clothes',\n",
              " 836: 'glory',\n",
              " 837: 'taught',\n",
              " 838: 'he’s',\n",
              " 839: 'bird',\n",
              " 840: 'fig',\n",
              " 841: 'wear',\n",
              " 842: 'destroy',\n",
              " 843: 'actions',\n",
              " 844: 'magnus',\n",
              " 845: 'floor',\n",
              " 846: 'hair',\n",
              " 847: 'survive',\n",
              " 848: 'fingers',\n",
              " 849: 'force',\n",
              " 850: 'ron',\n",
              " 851: 'goodbye',\n",
              " 852: 'rule',\n",
              " 853: 'families',\n",
              " 854: 'understanding',\n",
              " 855: 'self',\n",
              " 856: 'capable',\n",
              " 857: 'fox',\n",
              " 858: 'stuff',\n",
              " 859: 'herself',\n",
              " 860: 'burning',\n",
              " 861: 'spring',\n",
              " 862: 'naked',\n",
              " 863: 'sorrow',\n",
              " 864: 'doesn’t',\n",
              " 865: 'country',\n",
              " 866: 'wanting',\n",
              " 867: 'talking',\n",
              " 868: 'tells',\n",
              " 869: 'من',\n",
              " 870: 'chamber',\n",
              " 871: 'choices',\n",
              " 872: 'lifes',\n",
              " 873: 'bravery',\n",
              " 874: 'nonsense',\n",
              " 875: 'lack',\n",
              " 876: 'conscience',\n",
              " 877: 'pride',\n",
              " 878: 'reader',\n",
              " 879: 'reads',\n",
              " 880: 'lover',\n",
              " 881: 'horrible',\n",
              " 882: 'belief',\n",
              " 883: 'fully',\n",
              " 884: 'dumbledore',\n",
              " 885: 'constantly',\n",
              " 886: 'kept',\n",
              " 887: 'allow',\n",
              " 888: 'gold',\n",
              " 889: 'car',\n",
              " 890: 'cats',\n",
              " 891: 'blind',\n",
              " 892: 'bit',\n",
              " 893: 'bigger',\n",
              " 894: 'you’ll',\n",
              " 895: 'sound',\n",
              " 896: '2',\n",
              " 897: 'deepest',\n",
              " 898: 'warm',\n",
              " 899: 'writer',\n",
              " 900: 'greatness',\n",
              " 901: 'science',\n",
              " 902: 'character',\n",
              " 903: 'believed',\n",
              " 904: 'lucky',\n",
              " 905: 'awful',\n",
              " 906: 'job',\n",
              " 907: 'sorry',\n",
              " 908: 'hidden',\n",
              " 909: 'cold',\n",
              " 910: 'opinions',\n",
              " 911: 'easily',\n",
              " 912: 'somehow',\n",
              " 913: 'complete',\n",
              " 914: 'relationship',\n",
              " 915: 'surprise',\n",
              " 916: 'wed',\n",
              " 917: 'dangerous',\n",
              " 918: 'promise',\n",
              " 919: 'precisely',\n",
              " 920: 'realized',\n",
              " 921: 'offer',\n",
              " 922: 'create',\n",
              " 923: 'empty',\n",
              " 924: 'wild',\n",
              " 925: 'sadness',\n",
              " 926: 'lets',\n",
              " 927: 'neither',\n",
              " 928: 'hit',\n",
              " 929: 'killed',\n",
              " 930: 'peeta',\n",
              " 931: 'i’ve',\n",
              " 932: 'enemy',\n",
              " 933: 'feels',\n",
              " 934: 'tired',\n",
              " 935: 'teacher',\n",
              " 936: 'corner',\n",
              " 937: 'flowers',\n",
              " 938: 'missing',\n",
              " 939: 'parents',\n",
              " 940: 'return',\n",
              " 941: 'comfort',\n",
              " 942: 'suddenly',\n",
              " 943: 'depression',\n",
              " 944: 'eternal',\n",
              " 945: 'نصف',\n",
              " 946: 'created',\n",
              " 947: '“it',\n",
              " 948: 'theyll',\n",
              " 949: 'explain',\n",
              " 950: 'six',\n",
              " 951: 'cause',\n",
              " 952: 'admit',\n",
              " 953: 'onto',\n",
              " 954: 'sitting',\n",
              " 955: 'happening',\n",
              " 956: 'staring',\n",
              " 957: 'opened',\n",
              " 958: 'possibly',\n",
              " 959: 'whose',\n",
              " 960: 'answers',\n",
              " 961: 'drive',\n",
              " 962: 'differently',\n",
              " 963: 'ignore',\n",
              " 964: 'quiet',\n",
              " 965: 'clear',\n",
              " 966: 'brings',\n",
              " 967: 'mate',\n",
              " 968: 'yesterday',\n",
              " 969: 'till',\n",
              " 970: 'dogs',\n",
              " 971: 'dust',\n",
              " 972: 'fallen',\n",
              " 973: 'lead',\n",
              " 974: 'fit',\n",
              " 975: 'transform',\n",
              " 976: 'tessa',\n",
              " 977: 'pretending',\n",
              " 978: 'taking',\n",
              " 979: 'date',\n",
              " 980: 'list',\n",
              " 981: 'she’s',\n",
              " 982: 'pages',\n",
              " 983: 'likes',\n",
              " 984: 'understood',\n",
              " 985: 'favorite',\n",
              " 986: 'breath',\n",
              " 987: 'pure',\n",
              " 988: 'filled',\n",
              " 989: 'scars',\n",
              " 990: 'ordinary',\n",
              " 991: 'grateful',\n",
              " 992: 'literature',\n",
              " 993: 'sees',\n",
              " 994: 'advice',\n",
              " 995: 'parts',\n",
              " 996: 'simon',\n",
              " 997: 'faster',\n",
              " 998: 'fine',\n",
              " 999: 'fate',\n",
              " 1000: 'ugly',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "03dGbmfk-mLw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictor(model, tokenizer, text_input, max_len):\n",
        "  text = text_input.lower()\n",
        "\n",
        "  seq = tokenizer.texts_to_sequences([text])[0]\n",
        "  seq = pad_sequences([seq], maxlen=max_len, padding=\"pre\")\n",
        "  pred = model.predict(seq, verbose=0)\n",
        "\n",
        "  pred_index = np.argmax(pred)\n",
        "  return index_to_word[pred_index]"
      ],
      "metadata": {
        "id": "c2humZNf-_ia"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"life is\"\n",
        "next_word = predictor(lstm_model, tokenizer, seed_text, maxlen)\n",
        "next_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KJaeI4LLADeu",
        "outputId": "add0ae83-bd03-4bd1-b15c-3142d1eba065"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'not'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"you will\"\n",
        "next_word = predictor(lstm_model, tokenizer, seed_text, maxlen)\n",
        "next_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3kZniA7lAUwh",
        "outputId": "684523ea-d872-497e-96b8-8c5cd6524eef"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lose'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"what are you\"\n",
        "next_word = predictor(lstm_model, tokenizer, seed_text, maxlen)\n",
        "next_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ngnah7syBCT1",
        "outputId": "98610ec2-662f-48fe-c2e1-7647f0e43260"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'all'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"what are you\"\n",
        "next_word = predictor(lstm_model, tokenizer, seed_text, maxlen)\n",
        "next_word"
      ],
      "metadata": {
        "id": "AiZxg89XBGBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, seed_text, max_len, n_word):\n",
        "  for _ in range(n_word):\n",
        "    next_word = predictor(model, tokenizer, seed_text, max_len)\n",
        "    seed_text += \" \" + next_word\n",
        "  return seed_text"
      ],
      "metadata": {
        "id": "_9oexQU_BQR_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"the meaning of life\"\n",
        "print(generate_text(lstm_model, tokenizer, seed_text, maxlen, 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jEQHhJ9BsZ1",
        "outputId": "ef4d9d4e-cd88-400e-9267-5ef16ff2d458"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of life is not to let those who have not completely we\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"you are my\"\n",
        "print(generate_text(lstm_model, tokenizer, seed_text, maxlen, 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq02xV-tCBGj",
        "outputId": "f37590d6-43a7-43c7-8d5f-63b3e1b3ab85"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are my best friend as well as you — and much i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
        "  pickle.dump(tokenizer, f)"
      ],
      "metadata": {
        "id": "kSY0dQJSCmMc"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"max_len.pkl\", \"wb\") as f:\n",
        "  pickle.dump(maxlen, f)"
      ],
      "metadata": {
        "id": "etzuLnhRDApN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WXPsssB5DKkm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOvo1P6RPvfU8aqZUQYIinT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}